{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "from nltk import word_tokenize\n",
    "stop_words = stopwords.words('english')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import chardet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import copy\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"C:\\\\TextMining\\\\QAquiz\\\\input\\\\WebQA.csv\")\n",
    "df = df.dropna(how=\"any\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 3)\n",
      "Index(['qid', 'question', 'answer'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are Web Services?\n",
      "Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\n",
      "\n",
      "What are the different types of web services?\n",
      "There are two types of web services \n",
      "\n",
      "SOAP   It is an XML-based protocol for accessing web services.\n",
      "RESTful  It is an architectural style, not a protocol.\n",
      "\n",
      "What are the main features of SOAP?\n",
      "SOAP is a communication protocol.\n",
      "SOAP communicates between applications.\n",
      "SOAP is a format for sending messages.\n",
      "SOAP is designed to communicate via Internet.\n",
      "SOAP is platform independent.\n",
      "SOAP is language independent.\n",
      "SOAP is simple and extensible.\n",
      "SOAP allows you to get around firewalls.\n",
      "SOAP developed as a W3C standard\n",
      "\n",
      "What is RESTful web services?\n",
      "The REST stands for Representational State Transfer. It is an architectural style. It is not a protocol like SOAP\n",
      "\n",
      "What is SOA?\n",
      "SOA stands for Service Oriented Architecture. It is a design pattern to provide services to other application through protocol.\n",
      "\n",
      "What tools are used to test web services?\n",
      "SoapUI tool for testing SOAP and RESTful web services\n",
      "Poster for firefox browser\n",
      "Postman extension for Chrome\n",
      "\n",
      "What is the advantage of XML in web service?\n",
      "In Web service, an XML is used to tag the data, format the data.\n",
      "\n",
      "What is a remote procedure call (RPC)?\n",
      "The Remote procedure calls refer to the calls made to the methods which are hosted by related web service.\n",
      "\n",
      "Which language does UDDI use?\n",
      "The UDDI uses the language known as WSDL (Web Service Description Language).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 0 \n",
    "for i in range(a,a+9):\n",
    "    print(df.question[i])\n",
    "    print(df.answer[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(pd):\n",
    "  pd = pd.str.lower()\n",
    "  pd = pd.str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "  pd = pd.apply(lambda x: [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(x)])\n",
    "  pd = pd.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "  #pd = pd.apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "  return pd.str.join(' ')\n",
    "\n",
    "   # Function to convert  list to str \n",
    "def listToString(s):  \n",
    "    \n",
    "    # initialize an empty string \n",
    "    str1 = \"\"  \n",
    "    \n",
    "    # traverse in the string   \n",
    "    for ele in s:  \n",
    "        str1 += ele   \n",
    "    \n",
    "    # return string   \n",
    "    return str1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['o_len_q'] = df.question.apply(lambda x: len(str(x)))\n",
    "df['o_len_word_q'] = df.question.apply(lambda x: len(str(x).split()))\n",
    "df['o_len_a'] = df.answer.apply(lambda x: len(str(x)))\n",
    "df['o_len_word_a'] = df.answer.apply(lambda x: len(str(x).split()))\n",
    "df['o_processed_ans']=preprocess(df['answer'])\n",
    "df['o_plen_a'] = df.o_processed_ans.apply(lambda x: len(str(x)))\n",
    "df['o_plen_word_a'] = df.o_processed_ans.apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>o_len_q</th>\n",
       "      <th>o_len_word_q</th>\n",
       "      <th>o_len_a</th>\n",
       "      <th>o_len_word_a</th>\n",
       "      <th>o_processed_ans</th>\n",
       "      <th>o_plen_a</th>\n",
       "      <th>o_plen_word_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What are Web Services?</td>\n",
       "      <td>Web services are XML based information exchang...</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>197</td>\n",
       "      <td>25</td>\n",
       "      <td>web service xml based information exchange sys...</td>\n",
       "      <td>152</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What are the different types of web services?</td>\n",
       "      <td>There are two types of web services \\n\\nSOAP  ...</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>155</td>\n",
       "      <td>26</td>\n",
       "      <td>two type web service soap xml based protocol a...</td>\n",
       "      <td>103</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                       question  \\\n",
       "0    1                         What are Web Services?   \n",
       "1    2  What are the different types of web services?   \n",
       "\n",
       "                                              answer  o_len_q  o_len_word_q  \\\n",
       "0  Web services are XML based information exchang...       22             4   \n",
       "1  There are two types of web services \\n\\nSOAP  ...       45             8   \n",
       "\n",
       "   o_len_a  o_len_word_a                                    o_processed_ans  \\\n",
       "0      197            25  web service xml based information exchange sys...   \n",
       "1      155            26  two type web service soap xml based protocol a...   \n",
       "\n",
       "   o_plen_a  o_plen_word_a  \n",
       "0       152             19  \n",
       "1       103             15  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question? What are Web Services?\n",
      "Enter Answer Web services are XML based information exchange systems that use the Internet for direct application-to-application \n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter question? \")\n",
    "Answer_R= input(\"Enter Answer \")\n",
    "#df1 = {[question],[Answer_R]}\n",
    "df1 = {\n",
    "    'ques':[question],\n",
    "    'Answer_R':[Answer_R]}\n",
    " \n",
    "ques_answer=pd.DataFrame(df1,columns=['ques','Answer_R'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques</th>\n",
       "      <th>Answer_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are Web Services?</td>\n",
       "      <td>Web services are XML based information exchang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ques                                           Answer_R\n",
       "0  What are Web Services?  Web services are XML based information exchang..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_answer.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_answer['len_a'] = ques_answer.Answer_R.apply(lambda x: len(str(x)))\n",
    "ques_answer['len_word_a'] = ques_answer.Answer_R.apply(lambda x: len(str(x).split()))\n",
    "ques_answer['processed_ans']=preprocess(ques_answer['Answer_R'])\n",
    "ques_answer['plen_a'] = ques_answer.processed_ans.apply(lambda x: len(str(x)))\n",
    "ques_answer['plen_word_a'] = ques_answer.processed_ans.apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch Answer from the corpous\n",
    "\n",
    "o_ques_answer = df[df['question'].isin(ques_answer['ques'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>o_len_q</th>\n",
       "      <th>o_len_word_q</th>\n",
       "      <th>o_len_a</th>\n",
       "      <th>o_len_word_a</th>\n",
       "      <th>o_processed_ans</th>\n",
       "      <th>o_plen_a</th>\n",
       "      <th>o_plen_word_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What are Web Services?</td>\n",
       "      <td>Web services are XML based information exchang...</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>197</td>\n",
       "      <td>25</td>\n",
       "      <td>web service xml based information exchange sys...</td>\n",
       "      <td>152</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                question  \\\n",
       "0    1  What are Web Services?   \n",
       "\n",
       "                                              answer  o_len_q  o_len_word_q  \\\n",
       "0  Web services are XML based information exchang...       22             4   \n",
       "\n",
       "   o_len_a  o_len_word_a                                    o_processed_ans  \\\n",
       "0      197            25  web service xml based information exchange sys...   \n",
       "\n",
       "   o_plen_a  o_plen_word_a  \n",
       "0       152             19  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_ques_answer.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_ans=o_ques_answer['o_processed_ans'].tolist()\n",
    "ans=ques_answer['processed_ans'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['web service xml based information exchange system use internet direct application application interaction system include program object message document']\n",
      "['web service xml based information exchange system use internet direct application application']\n"
     ]
    }
   ],
   "source": [
    "print(o_ans)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_answer = nltk.word_tokenize(listToString(o_ans))\n",
    "answered = nltk.word_tokenize(listToString(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['web', 'service', 'xml', 'based', 'information', 'exchange', 'system', 'use', 'internet', 'direct', 'application', 'application', 'interaction', 'system', 'include', 'program', 'object', 'message', 'document']\n",
      "['web', 'service', 'xml', 'based', 'information', 'exchange', 'system', 'use', 'internet', 'direct', 'application', 'application']\n"
     ]
    }
   ],
   "source": [
    "print(original_answer)\n",
    "print(answered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(25 unique tokens: ['current', 'f1', 'international', 'masterâ€™s', 'mean']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "w2v_model = api.load(\"glove-wiki-gigaword-50\")\n",
    "similarity_matrix = w2v_model.similarity_matrix(dictionary)\n",
    "#print('similarity = %.4f' % similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `softcossim` (Function will be removed in 4.0.0, use gensim.similarities.termsim.SparseTermSimilarityMatrix.inner_product instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity = 0.4756\n"
     ]
    }
   ],
   "source": [
    "from gensim.matutils import softcossim\n",
    "\n",
    "similarity = softcossim(question1, question2, similarity_matrix)\n",
    "print('similarity = %.4f' % similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_q1'] = df.question1.apply(lambda x: len(str(x)))\n",
    "df['len_q2'] = df.question2.apply(lambda x: len(str(x)))\n",
    "df['diff_len'] = df.len_q1 - df.len_q2\n",
    "df['len_char_q1'] = df.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "df['len_char_q2'] = df.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "df['len_word_q1'] = df.question1.apply(lambda x: len(str(x).split()))\n",
    "df['len_word_q2'] = df.question2.apply(lambda x: len(str(x).split()))\n",
    "df['common_words'] = df.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>common_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>-37</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "\n",
       "                                           question2  is_duplicate  len_q1  \\\n",
       "0  What is the step by step guide to invest in sh...             0      66   \n",
       "1  What would happen if the Indian government sto...             0      51   \n",
       "\n",
       "   len_q2  diff_len  len_char_q1  len_char_q2  len_word_q1  len_word_q2  \\\n",
       "0      57         9           20           20           14           12   \n",
       "1      88       -37           21           29            8           13   \n",
       "\n",
       "   common_words  \n",
       "0            10  \n",
       "1             4  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "news_headline1 = \"Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\"\n",
    "news_headline2 = \"Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\"\n",
    "news_headline3 = \"Web services are XML based information  systems and use Internet for application interaction.They contain programs, objects, messages, or documents.\"\n",
    "news_headline4 = \"Web services Web services Web services XML Web services XML Internet \"\n",
    "\n",
    "news_headlines = [news_headline1, news_headline2, news_headline3, news_headline4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 tokens from news headlines:  ['Web', 'services', 'are', 'XML', 'based', 'information', 'exchange', 'systems', 'that', 'use']\n",
      "First 10 tokens from news headlines:  ['Web', 'services', 'are', 'XML', 'based', 'information', 'exchange', 'systems', 'that', 'use']\n",
      "First 10 tokens from news headlines:  ['Web', 'services', 'are', 'XML', 'based', 'information', 'systems', 'and', 'use', 'Internet']\n",
      "First 10 tokens from news headlines:  ['Web', 'services', 'Web', 'services', 'Web', 'services', 'XML', 'Web', 'services', 'XML']\n"
     ]
    }
   ],
   "source": [
    "news_headline1_tokens = nltk.word_tokenize(news_headline1)\n",
    "news_headline2_tokens = nltk.word_tokenize(news_headline2)\n",
    "news_headline3_tokens = nltk.word_tokenize(news_headline3)\n",
    "news_headline4_tokens = nltk.word_tokenize(news_headline4)\n",
    "\n",
    "for words in [news_headline1_tokens, news_headline2_tokens, news_headline3_tokens, news_headline4_tokens]:\n",
    "    print('First 10 tokens from news headlines: ', words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Tokens:\n",
      "['Web', 'services', 'are', 'XML', 'based', 'information', 'exchange', 'systems', 'that', 'use', 'the', 'Internet', 'for', 'direct', 'application-to-application', 'interaction', '.', 'These', 'systems', 'can', 'include', 'programs', ',', 'objects', ',', 'messages', ',', 'or', 'documents', '.', 'Web', 'services', 'are', 'XML', 'based', 'information', 'exchange', 'systems', 'that', 'use', 'the', 'Internet', 'for', 'direct', 'application-to-application', 'interaction', '.', 'These', 'systems', 'can', 'include', 'programs', ',', 'objects', ',', 'messages', ',', 'or', 'documents', '.', 'Web', 'services', 'are', 'XML', 'based', 'information', 'systems', 'and', 'use', 'Internet', 'for', 'application', 'interaction.They', 'contain', 'programs', ',', 'objects', ',', 'messages', ',', 'or', 'documents', '.', 'Web', 'services', 'Web', 'services', 'Web', 'services', 'XML', 'Web', 'services', 'XML', 'Internet']\n",
      "\n",
      "Original Input: ['Web', 'services', 'are', 'XML', 'based', 'information', 'exchange', 'systems', 'that', 'use', 'the', 'Internet', 'for', 'direct', 'application-to-application', 'interaction', '.', 'These', 'systems', 'can', 'include', 'programs', ',', 'objects', ',', 'messages', ',', 'or', 'documents', '.']\n",
      "Encoded by Label Encoder: [ 4 25  9  5 10 18 15 26 27 29 28  2 16 13  8 19  1  3 26 11 17 24  0 22\n",
      "  0 21  0 23 14  1]\n",
      "Encoded by OneHot Encoder:\n",
      "  (0, 4)\t1.0\n",
      "  (1, 25)\t1.0\n",
      "  (2, 9)\t1.0\n",
      "  (3, 5)\t1.0\n",
      "  (4, 10)\t1.0\n",
      "  (5, 18)\t1.0\n",
      "  (6, 15)\t1.0\n",
      "  (7, 26)\t1.0\n",
      "  (8, 27)\t1.0\n",
      "  (9, 29)\t1.0\n",
      "  (10, 28)\t1.0\n",
      "  (11, 2)\t1.0\n",
      "  (12, 16)\t1.0\n",
      "  (13, 13)\t1.0\n",
      "  (14, 8)\t1.0\n",
      "  (15, 19)\t1.0\n",
      "  (16, 1)\t1.0\n",
      "  (17, 3)\t1.0\n",
      "  (18, 26)\t1.0\n",
      "  (19, 11)\t1.0\n",
      "  (20, 17)\t1.0\n",
      "  (21, 24)\t1.0\n",
      "  (22, 0)\t1.0\n",
      "  (23, 22)\t1.0\n",
      "  (24, 0)\t1.0\n",
      "  (25, 21)\t1.0\n",
      "  (26, 0)\t1.0\n",
      "  (27, 23)\t1.0\n",
      "  (28, 14)\t1.0\n",
      "  (29, 1)\t1.0\n",
      "\n",
      "Original Input: ['Web', 'services', 'are', 'XML', 'based', 'information', 'exchange', 'systems', 'that', 'use', 'the', 'Internet', 'for', 'direct', 'application-to-application', 'interaction', '.', 'These', 'systems', 'can', 'include', 'programs', ',', 'objects', ',', 'messages', ',', 'or', 'documents', '.']\n",
      "Encoded by Label Encoder: [ 4 25  9  5 10 18 15 26 27 29 28  2 16 13  8 19  1  3 26 11 17 24  0 22\n",
      "  0 21  0 23 14  1]\n",
      "Encoded by OneHot Encoder:\n",
      "  (0, 4)\t1.0\n",
      "  (1, 25)\t1.0\n",
      "  (2, 9)\t1.0\n",
      "  (3, 5)\t1.0\n",
      "  (4, 10)\t1.0\n",
      "  (5, 18)\t1.0\n",
      "  (6, 15)\t1.0\n",
      "  (7, 26)\t1.0\n",
      "  (8, 27)\t1.0\n",
      "  (9, 29)\t1.0\n",
      "  (10, 28)\t1.0\n",
      "  (11, 2)\t1.0\n",
      "  (12, 16)\t1.0\n",
      "  (13, 13)\t1.0\n",
      "  (14, 8)\t1.0\n",
      "  (15, 19)\t1.0\n",
      "  (16, 1)\t1.0\n",
      "  (17, 3)\t1.0\n",
      "  (18, 26)\t1.0\n",
      "  (19, 11)\t1.0\n",
      "  (20, 17)\t1.0\n",
      "  (21, 24)\t1.0\n",
      "  (22, 0)\t1.0\n",
      "  (23, 22)\t1.0\n",
      "  (24, 0)\t1.0\n",
      "  (25, 21)\t1.0\n",
      "  (26, 0)\t1.0\n",
      "  (27, 23)\t1.0\n",
      "  (28, 14)\t1.0\n",
      "  (29, 1)\t1.0\n",
      "\n",
      "Original Input: ['Web', 'services', 'are', 'XML', 'based', 'information', 'systems', 'and', 'use', 'Internet', 'for', 'application', 'interaction.They', 'contain', 'programs', ',', 'objects', ',', 'messages', ',', 'or', 'documents', '.']\n",
      "Encoded by Label Encoder: [ 4 25  9  5 10 18 26  6 29  2 16  7 20 12 24  0 22  0 21  0 23 14  1]\n",
      "Encoded by OneHot Encoder:\n",
      "  (0, 4)\t1.0\n",
      "  (1, 25)\t1.0\n",
      "  (2, 9)\t1.0\n",
      "  (3, 5)\t1.0\n",
      "  (4, 10)\t1.0\n",
      "  (5, 18)\t1.0\n",
      "  (6, 26)\t1.0\n",
      "  (7, 6)\t1.0\n",
      "  (8, 29)\t1.0\n",
      "  (9, 2)\t1.0\n",
      "  (10, 16)\t1.0\n",
      "  (11, 7)\t1.0\n",
      "  (12, 20)\t1.0\n",
      "  (13, 12)\t1.0\n",
      "  (14, 24)\t1.0\n",
      "  (15, 0)\t1.0\n",
      "  (16, 22)\t1.0\n",
      "  (17, 0)\t1.0\n",
      "  (18, 21)\t1.0\n",
      "  (19, 0)\t1.0\n",
      "  (20, 23)\t1.0\n",
      "  (21, 14)\t1.0\n",
      "  (22, 1)\t1.0\n",
      "\n",
      "Original Input: ['Web', 'services', 'Web', 'services', 'Web', 'services', 'XML', 'Web', 'services', 'XML', 'Internet']\n",
      "Encoded by Label Encoder: [ 4 25  4 25  4 25  5  4 25  5  2]\n",
      "Encoded by OneHot Encoder:\n",
      "  (0, 4)\t1.0\n",
      "  (1, 25)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (3, 25)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (5, 25)\t1.0\n",
      "  (6, 5)\t1.0\n",
      "  (7, 4)\t1.0\n",
      "  (8, 25)\t1.0\n",
      "  (9, 5)\t1.0\n",
      "  (10, 2)\t1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "def transform(headlines):\n",
    "    tokens = [w for s in headlines for w in s ]\n",
    "    print()\n",
    "    print('All Tokens:')\n",
    "    print(tokens)\n",
    "\n",
    "    results = []\n",
    "    label_enc = sklearn.preprocessing.LabelEncoder()\n",
    "    onehot_enc = sklearn.preprocessing.OneHotEncoder()\n",
    "    \n",
    "    encoded_all_tokens = label_enc.fit_transform(list(set(tokens)))\n",
    "    encoded_all_tokens = encoded_all_tokens.reshape(len(encoded_all_tokens), 1)\n",
    "    \n",
    "    onehot_enc.fit(encoded_all_tokens)\n",
    "    \n",
    "    for headline_tokens in headlines:\n",
    "        print()\n",
    "        print('Original Input:', headline_tokens)\n",
    "        \n",
    "        encoded_words = label_enc.transform(headline_tokens)\n",
    "        print('Encoded by Label Encoder:', encoded_words)\n",
    "        \n",
    "        encoded_words = onehot_enc.transform(encoded_words.reshape(len(encoded_words), 1))\n",
    "        print('Encoded by OneHot Encoder:')\n",
    "        print(encoded_words)\n",
    "\n",
    "        results.append(np.sum(encoded_words.toarray(), axis=0))\n",
    "    \n",
    "    return results\n",
    "\n",
    "transformed_results = transform([\n",
    "    news_headline1_tokens, news_headline2_tokens, news_headline3_tokens, news_headline4_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Sentence: Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 0.00, Comparing Sentence: Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 0.00, Comparing Sentence: Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 3.87, Comparing Sentence: Web services are XML based information  systems and use Internet for application interaction.They contain programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 7.42, Comparing Sentence: Web services Web services Web services XML Web services XML Internet \n"
     ]
    }
   ],
   "source": [
    "#EEuclidean Distance\n",
    "\n",
    "print('Master Sentence: %s' % news_headlines[0])\n",
    "for i, news_headline in enumerate(news_headlines):\n",
    "    score = sklearn.metrics.pairwise.euclidean_distances([transformed_results[i]], [transformed_results[0]])[0][0]\n",
    "    print('-----')\n",
    "    print('Score: %.2f, Comparing Sentence: %s' % (score, news_headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Sentence: Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 1.00, Comparing Sentence: Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 1.00, Comparing Sentence: Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 0.79, Comparing Sentence: Web services are XML based information  systems and use Internet for application interaction.They contain programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 0.29, Comparing Sentence: Web services Web services Web services XML Web services XML Internet \n"
     ]
    }
   ],
   "source": [
    "#Cosine Similarity\n",
    "\n",
    "print('Master Sentence: %s' % news_headlines[0])\n",
    "for i, news_headline in enumerate(news_headlines):\n",
    "    score = sklearn.metrics.pairwise.cosine_similarity([transformed_results[i]], [transformed_results[0]])[0][0]\n",
    "    print('-----')\n",
    "    print('Score: %.2f, Comparing Sentence: %s' % (score, news_headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Sentence: Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 1.00, Comparing Sentence: Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 1.00, Comparing Sentence: Web services are XML based information exchange systems that use the Internet for direct application-to-application interaction. These systems can include programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 0.19, Comparing Sentence: Web services are XML based information  systems and use Internet for application interaction.They contain programs, objects, messages, or documents.\n",
      "-----\n",
      "Score: 0.00, Comparing Sentence: Web services Web services Web services XML Web services XML Internet \n"
     ]
    }
   ],
   "source": [
    "#Jaccard Similarity\n",
    "\"\"\"\n",
    "    Finding the posistion (from lookup table) of word instead of using 1 or 0\n",
    "    to prevent misleading of the meaning of \"common\" word\n",
    "\"\"\"\n",
    "\n",
    "def calculate_position(values):\n",
    "    x = []\n",
    "    for pos, matrix in enumerate(values):\n",
    "        if matrix > 0:\n",
    "            x.append(pos)\n",
    "    return x\n",
    "\n",
    "\"\"\"\n",
    "    Since scikit-learn can only compare same number of dimension of input. \n",
    "    Add padding to the shortest sentence.\n",
    "\"\"\"\n",
    "def padding(sentence1, sentence2):\n",
    "    x1 = sentence1.copy()\n",
    "    x2 = sentence2.copy()\n",
    "    \n",
    "    diff = len(x1) - len(x2)\n",
    "    \n",
    "    if diff > 0:\n",
    "        for i in range(0, diff):\n",
    "            x2.append(-1)\n",
    "    elif diff < 0:\n",
    "        for i in range(0, abs(diff)):\n",
    "            x1.append(-1)\n",
    "    \n",
    "    return x1, x2    \n",
    "\n",
    "y_actual = calculate_position(transformed_results[0])\n",
    "\n",
    "print('Master Sentence: %s' % news_headlines[0])\n",
    "for i, news_headline in enumerate(news_headlines):\n",
    "    y_compare = calculate_position(transformed_results[i])\n",
    "    x1, x2 = padding(y_actual, y_compare)\n",
    "    score = sklearn.metrics.jaccard_similarity_score(x1, x2)\n",
    "    print('-----')\n",
    "    print('Score: %.2f, Comparing Sentence: %s' % (score, news_headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
